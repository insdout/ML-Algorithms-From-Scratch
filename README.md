# ML Algorithms From Scratch

This repository contains implementations of various machine learning algorithms from scratch using Python. The implementations are located in the `mllib` directory, and example tutorials can be found in the `tutorials` directory.

## Table of Contents

- [Introduction](#introduction)
- [Repository Structure](#repository-structure)
- [Algorithms](#algorithms)
- [Tutorials](#tutorials)
- [Contributing](#contributing)
- [License](#license)

## Introduction

Implementing machine learning algorithms from scratch can be a great way to deepen your understanding of the underlying concepts and algorithms. This repository provides a collection of machine learning algorithms implemented in Python without relying on external libraries.

By studying and experimenting with these implementations, you can gain insights into the inner workings of popular machine learning algorithms and customize them to suit your specific needs.

## Repository Structure

The repository has the following structure:
```
├── mllib
|   ├── __init__.py
│   ├── base.py
│   ├── decision_tree.py
│   ├── linear_regression.py
│   ├── logistic_regression.py
│   └── sgd.py
├── README.md
└── tutorials
    ├── Decision_Trees.ipynb
    ├── Gradient_Descend_Adam_RMSProp.ipynb
    ├── Linear_Regression.ipynb
    └── SVD QR Spectral Decomposition.ipynb
```

The `mllib` directory contains the implementations of machine learning algorithms. Each algorithm is implemented in a separate Python file.

The `tutorials` directory contains example notebooks demonstrating the usage of the implemented algorithms. These tutorials provide step-by-step explanations and code examples to help you understand and apply the algorithms in practice.

## Algorithms

Here are some of the machine learning algorithms implemented in this repository:

- `base.py`: Contains the base classes and utilities used by other algorithms.
- `decision_tree.py`: Implements the decision tree algorithm for classification and regression tasks.
- `random_forest.py`: Contains the implementation of Random Forest.
- `linear_regression.py`: Provides implementations of linear regression.
- `logistic_regression.py` : Is implementation of logistic regression models.
- `sgd.py`: Implements the stochastic gradient descent optimization algorithm.

Feel free to explore the implementations, experiment with different algorithms, and customize them to meet your specific requirements.

## Tutorials

The `tutorials` directory contains Jupyter notebooks that demonstrate the usage of the implemented algorithms. Here are some of the tutorials available:

- `Decision_Trees.ipynb`: Illustrates the decision tree algorithm and its application in classification tasks.
- `Gradient_Descend_Adam_RMSProp.ipynb`: Explains gradient descent optimization techniques like Adam and RMSProp.
- `Linear_Regression.ipynb`: Demonstrates the linear regression algorithm for predicting continuous variables.
- `SVD QR Spectral Decomposition.ipynb`: Covers singular value decomposition, QR decomposition, and spectral decomposition.

Feel free to explore the tutorials and run the code to gain a better understanding of how the algorithms work and how to use them in practice.

## Contributing

Contributions to this repository are welcome! If you have any suggestions, improvements, or bug fixes, please feel free to open an issue or submit a pull request. Let's collaborate to make these machine learning implementations even better.

## License

This project is licensed under the [MIT License](LICENSE).

---

TODO: Algorithms to add.
- ~~Add Logistic Regression~~
- Add Gradient Boosting
- ~~Add Random Forest~~
- Add EM Algorithm
- Add Naive Bayess
- Add KNN
- Add SVM
- Add Spectral Clustering
- Add RMSProp
- Add Adam
- Add KNeighbors
- Add SVD
- Add QR
- Add matrix inverse via SVD
- Add eigendecomposition
- Add PCA  


---
TODO: General things.

- [ ] Add comments and docstrings  
- [ ] Refactor as package


